---
title: "SMR over time (year and day/night)"
author: "Amber Lee"
date: "December 2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```


# Set up (from 1 Set up SMR)
    
```{r load libraries, message = FALSE}

library(RMySQL)

library(tidyverse)
library(tidyr)
library(broom)
library(lubridate)
library(stringr)
library(kableExtra)
library(data.table) # for transposing coordinates

library(XML)
library(RCurl)
library(lutz)
library(suncalc)

```

```{r connect to sql, include = FALSE}

con <- dbConnect(
  MySQL(), host = "traffic.st47s.com", user = "student", 
  password = "insert password here :)", dbname = "insert database here :)")

```

```{r query n% sample of all datasets}

dataset_names <- dbGetQuery(con, "SHOW TABLES")[[1]]

# remove datasets with "_" in the name
dataset_names <- dataset_names[str_detect(dataset_names, "_", negate = TRUE)]

query_sample <- function(dataset_str, percent){
  # input is dataset_str (str) with dataset name, and percent (dbl) for the random sample %
  # output is the dataframe with a column added for the name of dataset and character NA's
  # replaced with NA's
  # global variable con is the SQL connection
  
  command <- paste("SELECT * FROM", dataset_str, "WHERE rand() <=", percent, 
                   # in SQL, filter for vehicular stops
                   " AND type = 'vehicular'",
                   sep = " ")

  df <- dbGetQuery(con, command) %>% mutate(dataset_name = dataset_str)
  
  # do not consider empty datasets
  if (dim(df)[1] == 0){
    return(NULL)
  }
  
  # replace character NA's with NA
  if (sum(is.na(df) == 0)){
    
    df[df == "NA"] = NA

  }
  
  return(df %>% dplyr::select(-type))
  
}

dataset_lst <- lapply(dataset_names, query_sample, 0.15)

# remove empty datasets through logical indexing
dataset_lst <- dataset_lst[sapply(dataset_lst, function(x) isTRUE(nrow(x) > 0))]

```

```{r}

check_nonempty <- function(var, dataset, n_obsv){
  # helper function for removing empty columns
    
  # the function environment has the parameter dataset
  col_str <- paste("dataset$", var, sep = "")
  col <- eval(parse(text = col_str))
  isCollected <- sum(is.na(col)) < n_obsv
  
  return(isCollected)
  
}

remove_empty_col <- function(dataset){
  # a variable is 'collected' if there is a column for it in the dataset
  # but being collected doesn't imply nonempty
  
  collected_var <- names(dataset)
  n_obsv <- dim(dataset)[1]
  
  nonempty_bools <- unlist(lapply(collected_var, check_nonempty, dataset, n_obsv))
  
  # use logial indexing!
  nonempty_var <- collected_var[nonempty_bools]
  
  ## in case i need this information
  # empty_var <- collected_var[!nonempty_bools]
  
  return(dataset %>% dplyr::select({{ nonempty_var }}))
  
}

dataset_lst <- lapply(dataset_lst, remove_empty_col)

```

```{r}

myfilter_for <- function(dataset, var_vect, need_containment){
  # if need_containment is true, then function only returns
  # datasets containing ALL variables specified in var_vect
  
  # need_containment = TRUE results in more restrictive filtering
  
  dataset_var <- names(dataset)
  intersection <- var_vect[var_vect %in% dataset_var]
  
  if (need_containment){
    
    if (length(intersection) == length(var_vect)) {
      # embrace syntax from dplyr programming
      return(dataset %>% dplyr::select({{ var_vect }}))
    } else {
      return(NULL)
    }
    
  } else if (!need_containment){
    
    if (length(intersection > 0)) {
      # embrace syntax from dplyr programming
      return(dataset %>% dplyr::select({{ intersection }}))
    } else{
      return(NULL)
    }
    
  }
  
}

```

```{r}

dataset_containing <- function(dataset, var_vect){
  # var_vect is str with the variables we WANT
  # returns the whole dataset
  
  if(var_vect %in% names(dataset)){
    return(dataset)
    
  } else {
    return(NULL)
    
  }
  
}

```

```{r search for specific dataset}

find_dataset <- function(dataset, name_str){
  
  if(dim(dataset)[1] <= 1){
    return(NULL)
  }
  
  if(dataset$dataset_name[1] == name_str){
    return(dataset)
  }
  
}

mysearch_dataset <- function(dataset_list, name_str){
  
  df <- lapply(dataset_list, find_dataset, name_str)
  df <- df[sapply(df, function(x) isTRUE(nrow(x) > 0))]
  
  return(df[[1]])
  
}

```

```{r}

check_missing <- function(n_threshold, df){
  
  col <- df %>% 
    mutate("isMissing_{{ n_threshold }}" := case_when(missing >= n_threshold ~ TRUE,
                                                TRUE ~ FALSE)) %>%
    select(starts_with("isMissing"))

  return(col)

}

countMissing <- function(dataset, n_threshold, exclude_bool, exclude_var){
  # <n_threshold> is used to classify the observations with
  # at least n_threshold missing values as completely missing
  
  # <exclude_var> is str specifying which variables we don't count for NA's

  n_var <- dim(dataset)[2]
  
  if (exclude_bool){
    missing <- list(missing = rowSums(is.na(dataset %>% select(-all_of(exclude_var)))))
    
  } else {
    missing <- list(missing = rowSums(is.na(dataset)))
    
  }
  
  dataset <- dataset %>%
    bind_cols(list(missing), .id = NULL) %>% 
    mutate(stop_missing_rate = missing/n_var)
  
  dataset <- dataset %>%
    # check_missing operates on dataset with missingness already counted
    bind_cols(lapply(1:n_threshold, check_missing, dataset))
 
  return(as.data.frame(dataset))

}

missing_lst <- lapply(dataset_lst, countMissing, 1, FALSE)

```

```{r top fifteen freq variables}

# 15 most frequently recorded variables
freq_var <- data.frame("var" = unlist(lapply(dataset_lst, function(dataset) names(dataset)))) %>%
  group_by(var) %>%
  summarize(count = n(), .groups = "drop") %>%
  # drop type (either pedestrian or vehicular)
  filter(var != "type" & str_detect(var, "row", negate = TRUE)) %>%
  # could make this function that returns top n var
  slice_max(count, n = 16) %>%
  pull(var)

```

# SMR by week (throughout years)

We do *not* require containment when we use `myfilter_for`.

```{r filter for freq variables}

date_lst <- lapply(dataset_lst, myfilter_for, freq_var, FALSE)

# filtering OUT datasets that don't record date
date_lst <- lapply(date_lst, dataset_containing, "date")
date_lst <- date_lst[sapply(date_lst, function(x) isTRUE(nrow(x) > 0))]

```

```{r SMR by week}

# helper function
summarizeMissingTemporally <- function(dataset){
  
  dataset <- dataset %>%
    mutate(nice_date = ymd(date),
           nice_week = ymd(cut(nice_date, "week"))) %>%
    select(dataset_name, nice_week, stop_missing_rate) %>%
    ungroup() %>%
    group_by(nice_week, dataset_name) %>%
    summarize(avg_SMR = mean(stop_missing_rate), stop_count = n(), .groups = "drop")

  return(dataset)
  
}

makeDF.SMRByDate <- function(date_list){
  
  # count NA
  date_list <- lapply(date_list, countMissing, 1, TRUE, "date")
  
  # summarize
  date_list <- lapply(date_list, summarizeMissingTemporally)
  
  state_df <- data.frame(state = state.abb, region = state.region)
  
  southern_str <- state_df$state[state_df$region == "South"]
  west_str <- state_df$state[state_df$region == "West"]
  northeast_str <- state_df$state[state_df$region == "Northeast"]
  northcent_str <- state_df$state[state_df$region == "North Central"]
  
  nvar_per_dataset <- data.frame(dataset_name = sapply(dataset_lst, 
                                             function(dataset) dataset$dataset_name[1]),
                       n_var = sapply(dataset_lst, 
                                      function(dataset) length(names(dataset))))
  
  # make df just include date and SMR
  date_df <- bind_rows(date_list) %>%
    mutate(state_abb = substr(dataset_name, 1, 2),
           region = case_when(state_abb %in% southern_str ~ "South",
                              state_abb %in% west_str ~ "West",
                              state_abb %in% northeast_str ~ "Northeast",
                              state_abb %in% northcent_str ~ "North Central",
                              TRUE ~ "No regioned (error!)")) %>%
    #something off about this left join
    left_join(nvar_per_dataset, by = "dataset_name")
  
  return(date_df)
  
}

date_df <- makeDF.SMRByDate(date_lst)

```

```{r visualize}

ggplot_date <- function(date_dataset, region_or_dataset){
  
  plot_region <- function(name){
    
    p <- date_dataset %>%
      filter(region == name) %>%
      ggplot() +
      geom_point(aes(x = nice_week, y = avg_SMR, 
                     color = dataset_name), alpha = .8) +
      ggtitle(paste(name, "weekly SMR over time"))
    
    ggsave(paste(name, "weekly SMR.png"), p)
    return(p)
    
  }
  
  plot_dataset <- function(name){
    
    p <- date_dataset %>%
      filter(dataset_name == name) %>%
      ggplot() +
      geom_point(aes(x = nice_week, y = avg_SMR), alpha = .8) +
      ggtitle(paste(name, "weekly SMR over time"))

    ggsave(paste(name, "weekly SMR.png"), p)
    return(p)
    
  }
  
  if (region_or_dataset == "region"){
    region_names <- date_dataset %>% distinct(region) %>% pull (region)
    plots <- lapply(region_names, plot_region)
    
  } else if (region_or_dataset == "dataset"){
    dataset_names <- date_dataset %>% distinct(dataset_name) %>% pull(dataset_name)
    plots <- lapply(dataset_names, plot_dataset)
    
  } else {return(stop("typo in region_or_dataset"))}

  return(plots)
  
}

ggplot_date(date_df, "region")
ggplot_date(date_df, "dataset")

```

* SMR and its spread is different throughout the years
* the roughly-discernible average SMR can have level changes (Iowa statewide) or have gradual sloping changes 
* a low missingness rate isn't indicative of a *good* data set. example is CA los angeles -- the dataset records very few variable with a consistenly near-0 SMR. but no discrimination analysis tests can be done on it because it doesn't record subject_race!
* some datasets put in all their data by the month, so the dates are actually all inaccurate because the date of the traffic stop is actually when the data are entered, not when the stop takes place!

### What is wrong with ORstatewide?

Oregon records its stops by the year. So there are only 5 data points for the 5 years 2010 to 2014. 

```{r, eval = FALSE}

mysearch_dataset(dataset_lst, "ORstatewide") %>% distinct(date)

```

# SMR by night/day, throughout years

## Set up 

To add the variable `day_night`, we find the sunset, sunrise, and intertwilight times and categorize each traffic stop as having occurred in the darkness, in the sunlight, or during an ambiguous twilight time.

#### Filter datasets

For *time of day* analysis, we need variables `date` *and* `time`. We build on the filtering from the previous section.

```{r}

# filtering OUT datasets that don't record time
time_lst <- lapply(dataset_lst, dataset_containing, c("time", "date"))
time_lst <- time_lst[sapply(time_lst, function(x) isTRUE(nrow(x) > 0))]

```

#### Find the lat/lng for each dataset (city and/or state) 

```{r}

makeDF.Coordinates <- function(dataset_lst){
  
  pull_location_str <- function(dataset, for_URL){
    # for_URL is a boolean indicating if pulling the location_str
    # for a URL or not
    
    name <- dataset$dataset_name[1]
    
    if(for_URL){
        
      # extract lowecase letters of name
      check <- str_extract(name, "[a-z]+")
      state <- state.name[grep(str_sub(name, 1,2), state.abb)]
      
      if(check == "statewide" | check == "state"){
        
        url_name <- gsub(" ", "+", state.name[grep(str_sub(name, 1,2), state.abb)])
        # return full name of the state
        
        return(url_name)
        
      } else {
        
        url_name <- gsub(" ", "+", paste(check, state))
        return(url_name)
          
      }
    
    }
  
  # otherwise just turn dataset_name, as it is formatted in the dataset
  return(name)
  
}

  location_str_URL <- lapply(time_lst, pull_location_str, TRUE)
  
  # scraper function to fetch coordinates from city string
  get_coordinates <- function(city){
  
    # city is a string
  
    url_str <- paste("http://www.google.com/search?q=latitude+and+longitude+of+",
               city, sep = "")
  
    doc <- htmlParse(getURL(url_str))
  
    # class = BNeawe iBp4i AP7Wnd retrieves the coordinates
    coordinates <- xpathSApply(doc, "//div[@class='BNeawe iBp4i AP7Wnd']", xmlValue)[1]
  
    clean_coordinates <- str_split(coordinates, ", ")[[1]]
  
    # use regular expressions to extract lat and lng
    lat <- as.numeric(str_extract(clean_coordinates[1], "\\d+\\.*\\d*"))
    # multiple long by -1 b/c...?
    long <- -1*as.numeric(str_extract(clean_coordinates[2], "\\d+\\.*\\d*"))
  
    final_coordinates <- c(lat, long)
    return(final_coordinates)
  
  }
  
  # find lat/long information using get_coordinates function and relevant_dataset_names df
  coordinates_lst <- lapply(location_str_URL, get_coordinates)
  
  # bind lat/long information with relevant_dataset_names
  coordinates_df <- data.table::transpose(data.frame(coordinates_lst)) %>%
    # join with dataset_names
    bind_cols(data.table::transpose(data.frame(lapply(time_lst, pull_location_str, FALSE)))) %>%
    rename(lat = V1...1, lng = V2, dataset_name = V1...3)
  
  return(coordinates_df)
  
}


coordinates_df <- makeDF.Coordinates(time_lst)

```
(can we use lat/lng from other packages like tigris... other geolocators probably exist)

#### Add day/night/twilight variable

```{r}

# helper function for add_day_night, returns minute of the day
time_to_minute <- function(time){
  # time can be str
  lubridate::hour(hms(time)) * 60 + lubridate::minute(hms(time))
}

# calculate sunset, sunrise, dusk, and dawn times
oursunriseset <- function(latitude, longitude, date, timezone, direction) {
  
  date.lat.long <- data.frame(date = date, lat = latitude, lon = longitude)
  
  if(direction == "sunset"){
    # call getSunlightTimes from the lutz package
    getSunlightTimes(data = date.lat.long, keep=direction, tz=timezone)$sunset
    
  } else if(direction == "sunrise"){
    getSunlightTimes(data = date.lat.long, keep=direction, tz=timezone)$sunri 
    
  } else if (direction == "dusk"){
    getSunlightTimes(data = date.lat.long, keep=direction, tz=timezone)$dusk
    
  } else if (direction == "dawn"){
    getSunlightTimes(data = date.lat.long, keep=direction, tz=timezone)$dawn
  }
}

add_day_night <- function(dataset, coord_df){
    
  dataset_name_str <- dataset$dataset_name[1]

  # filter for lat/long information of dataset
  coord_df <- coord_df %>% filter(dataset_name == dataset_name_str)
  
  # intialize lat, long, tz information
  lat <- coord_df$lat[1]
  lng <- coord_df$lng[1]
  time_zone <- lutz::tz_lookup_coords(lat, lng, warn = F)
  
  # use lubridate to clean date type in dataset
  dataset <- dataset %>%
    filter(!is.na(time) & !is.na(date)) %>%
    mutate(date = as.Date(ymd(date, tz = time_zone)),
           stop_minute = time_to_minute(time))
  
  # df for dawn, sunrise, sunset, and dusk times for distinct dates
  sunriseset_times <- dataset %>% 
    filter(!is.na(date)) %>%
    distinct(date) %>% 
    mutate(dawn_hms = format(oursunriseset(lat, lng, date, 
                                           time_zone, direction = "dawn"), 
                             "%H:%M:%S"),
           sunrise_hms = format(oursunriseset(lat, lng, date, 
                                              time_zone, direction = "sunrise"),
                               "%H:%M:%S"),
           sunset_hms = format(oursunriseset(lat, lng, date, 
                                             time_zone, direction = "sunset"), 
                               "%H:%M:%S"),
           dusk_hms = format(oursunriseset(lat, lng, date, 
                                           time_zone, direction = "dusk"), 
                             "%H:%M:%S"),
           dawn = time_to_minute(dawn_hms),
           sunrise = time_to_minute(sunrise_hms),
           sunset = time_to_minute(sunset_hms),
           dusk = time_to_minute(dusk_hms))

  # filter dataset for stops occurring during window_of_stop 
  dataset <- dataset %>% 
    left_join(sunriseset_times, by = "date") %>%
    mutate(day_night = case_when(stop_minute >= dawn & 
                                   stop_minute < sunrise ~ "twilight morning",
                                 stop_minute >= sunrise & 
                                   stop_minute < sunset ~ "day",
                                 stop_minute >= sunset & 
                                   stop_minute < dusk ~ "twilight evening",
                                 stop_minute >= dusk | 
                                   stop_minute < dawn ~ "night",
                                 TRUE ~ "missing"))
  
}

sunriseset_lst <- lapply(time_lst, add_day_night, coordinates_df)


```

We can visualize the newly added day and night variables by plotting the stop minute over the date and color code by the labels day, night, and twilight. The following plot is for San Bernadino.

```{r check that we label time of day correctly, eval = FALSE}

ggplot(data = sunriseset_lst[[1]]) +
  geom_point(aes(x = date, y = stop_minute, color = day_night), alpha = .1)

```

## Time analysis

```{r plot}

summarizeSMRDayNight <- function(dataset){
    # calculate average SMR per month for day and night
    # find_diff_bool indicates if we want to SPREAD the dataset
    
    dataset <- dataset %>% 
      mutate(nice_month = ymd(cut(ymd(date), "month"))) %>%
      group_by(dataset_name, nice_month, day_night) %>%
      # filter out stops occurring during twilight
      filter(str_detect(day_night, "twilight", negate = TRUE)) %>%
      summarize(avg_SMR = mean(stop_missing_rate), .groups = "drop")
    
    return(dataset)
    
  }

makeDF.SMRTime <- function(sunriseset_list, find_diff_bool){
  
  # filter away the helper columns like stop_minute and dusk_hms
  sunriseset_list <- lapply(sunriseset_list, myfilter_for, c(freq_var, "day_night"), FALSE)
  
  # count NA
  sunriseset_list <- lapply(sunriseset_list, countMissing, 1, TRUE,
                            c("time", "day_night", "date"))
  
  # summarize SMR per month by day and night
  sunriseset_list <- lapply(sunriseset_list, summarizeSMRDayNight)
  
  sunriseset_df <- bind_rows(sunriseset_list)
  
  if (find_diff_bool){
    
    sunriseset_df <- sunriseset_df %>%
      spread(key = day_night, value = avg_SMR) %>%
      mutate(diff_SMR = day - night)
    
  }
  
  return(sunriseset_df)
  
}

sunriseset_df <- makeDF.SMRTime(sunriseset_lst, FALSE)
sunrisesetdiff_df <- makeDF.SMRTime(sunriseset_lst, TRUE)

ggplot_sunriseset <- function(sunriseset_dataset, variable_str){
  
  plot_avg <- function(name){
    
    p <- sunriseset_dataset %>%
      filter(dataset_name == name) %>%
      ggplot(aes(x = nice_month, y = avg_SMR)) +
      geom_point() +
      facet_wrap(~ day_night) +
      ggtitle(paste("Average monthly SMR of", name)) +
      labs(x = "Date", y = "Average SMR")
    
    ggsave(paste(name, "SMR by day and night.png"), p)
    
    return(p)
    
  }
  
  plot_diff <- function(name){
    
    p <- sunriseset_dataset %>%
      filter(dataset_name == name) %>%
      ggplot(aes(x = nice_month, y = diff_SMR)) +
      geom_point() +
      ggtitle(paste("Difference in SMR of", name, 
                    "Between Day and Night per month")) +
      labs(x = "Date", y = "Difference in SMR")
    
    ggsave(paste(name, "SMR day and night.png"), p)
    
    return(p)
    
  }
  
  dataset_name <- sunriseset_dataset %>% distinct(dataset_name) %>% pull(dataset_name)
  
  if (variable_str == "avg_SMR"){
    plots <- lapply(dataset_name, plot_avg)
    
  } else if (variable_str == "diff_SMR") {
    plots <- lapply(dataset_name, plot_diff)
    
  } else {stop("typo in variable_str!")}

  return(plots)
  
}

ggplot_sunriseset(sunriseset_df, "avg_SMR")

ggplot_sunriseset(sunrisesetdiff_df, "diff_SMR")


```


# Toy log reg

outcome = race*age + gender + 4-hour period of the day + day of the week + year ???

```{r, eval = FALSE}
sc_lst <- lapply(sunriseset_lst, myfilter_for, c("subject_race", "dataset_name", "time", "date", "search_conducted"), TRUE)

sc_lst <- sc_lst[sapply(sc_lst, function(x) isTRUE(nrow(x) > 0))]

sc_lst <- lapply(sc_lst, outcome_clean, "search_conducted")

sapply(sc_lst, function(x) x$dataset_name[1])

```


```{r, eval = FALSE}
am_lst <- lapply(sunriseset_lst, myfilter_for, c("subject_race", "dataset_name", "time", "date", "arrest_made"), TRUE)

am_lst <- am_lst[sapply(am_lst, function(x) isTRUE(nrow(x) > 0))]

am_lst <- lapply(am_lst, outcome_clean, "arrest_made")

sapply(am_lst, function(x) x$dataset_name[1])

```

```{r TNnash logistic pre post 2014, eval = FALSE}

# pre 2014-02-10 0% to 1%
# lat/lng

TNnash <- mysearch_dataset(sunriseset_lst, "TNnashville") %>%
  mutate(day_week = as.factor(wday(ymd(date))),
         hour = lubridate::hour(hms(time)),
         hour = case_when(hour <= 4 ~ 1,
                          hour <= 8 & hour > 4 ~ 2,
                          hour <= 12 & hour > 8 ~ 3,
                          hour <= 16 & hour > 12 ~ 4,
                          hour <= 20 & hour > 16 ~ 5,
                          hour > 20 ~ 6),
         hour = as.factor(hour),
         subject_age = as.numeric(subject_age),
         subject_race = as.factor(subject_race))

TNnash <- outcome_clean(TNnash, "arrest_made")

TNpre <- TNnash %>% 
  filter(date < ymd("2014-02-10"))

TNpost <- TNnash %>% 
  filter(date > ymd("2014-02-10"))

```

\newpage 
```{r, eval = FALSE}
fit_TNpre <- glm(arrest_made ~ subject_race + subject_age + subject_sex + day_week + hour, data = TNpre, family = "binomial")
tidy(fit_TNpre) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

\newpage 
```{r, eval = FALSE}
fit_TNpost <- glm(arrest_made ~ subject_race +subject_age + subject_sex + day_week + hour, data = TNpost, family = "binomial")
tidy(fit_TNpost) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

\newpage 
```{r, eval = FALSE}
fit_TN <- glm(arrest_made ~ subject_race +subject_age + subject_sex + day_week + hour, data = TNnash, family = "binomial")
tidy(fit_TN) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

```{r NCraleigh daynight, eval = FALSE}

NCraleigh <- mysearch_dataset(sunriseset_lst, "NCraleigh") %>%
  mutate(day_week = as.factor(wday(ymd(date))),
         hour = lubridate::hour(hms(time)),
         hour = case_when(hour <= 4 ~ 1,
                          hour <= 8 & hour > 4 ~ 2,
                          hour <= 12 & hour > 8 ~ 3,
                          hour <= 16 & hour > 12 ~ 4,
                          hour <= 20 & hour > 16 ~ 5,
                          hour > 20 ~ 6),
         hour = as.factor(hour),
         subject_age = as.numeric(subject_age),
         subject_race = as.factor(subject_race))

NCraleigh <- outcome_clean(NCraleigh, "arrest_made")
NCraleigh <- outcome_clean(NCraleigh, "search_conducted")

NCday <- NCraleigh %>% filter(day_night == "day")

NCnight <- NCraleigh %>% filter(day_night == "night")

```

\newpage 
```{r, eval = FALSE}
fit_NCday <- glm(arrest_made ~ subject_race +subject_age + subject_sex + day_week, data = NCday, family = "binomial")
tidy(fit_NCday) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

\newpage 
```{r, eval = FALSE}
fit_NCnight <- glm(arrest_made ~ subject_race + subject_age + subject_sex + day_week, data = NCnight, family = "binomial")
tidy(fit_NCnight) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

\newpage 
```{r, eval = FALSE}
fit_NC <- glm(arrest_made ~ subject_race + subject_age + subject_sex + day_week, data = NCraleigh, family = "binomial")
tidy(fit_NC) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```
\newpage 
now for search_conducted
```{r, eval = FALSE}
fit_NCday <- glm(search_conducted ~ subject_race + subject_age + subject_sex + day_week, data = NCday, family = "binomial")
tidy(fit_NCday) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

\newpage 
```{r, eval = FALSE}
fit_NCnight <- glm(search_conducted ~ subject_race + subject_age + subject_sex + day_week, data = NCnight, family = "binomial")
tidy(fit_NCnight) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

\newpage 
```{r, eval = FALSE}
fit_NC <- glm(search_conducted ~ subject_race + subject_age + subject_sex + day_week, data = NCraleigh, family = "binomial")
tidy(fit_NC) %>%
  kbl(booktabs = T) %>%
  kableExtra::landscape()

```

```{r WAseattle, eval = FALSE}

WAseattle <- mysearch_dataset(sunriseset_lst, "WAseattle")  %>%
  mutate(day_week = as.factor(wday(ymd(date))),
         hour = lubridate::hour(hms(time)),
         hour = case_when(hour <= 4 ~ 1,
                          hour <= 8 & hour > 4 ~ 2,
                          hour <= 12 & hour > 8 ~ 3,
                          hour <= 16 & hour > 12 ~ 4,
                          hour <= 20 & hour > 16 ~ 5,
                          hour > 20 ~ 6),
         hour = as.factor(hour),
         subject_age = as.numeric(subject_age),
         subject_race = as.factor(subject_race))

WAseattle %>% group_by(arrest_made, subject_race) %>% summarize(count = n())

```




# scraps 

```{r, eval = FALSE}
#year
SDstatewide <- mysearch_dataset(date_lst, "SDstatewide") # 2015-08-31 14% to ~ 0%
  # location is different
NHstatewide <- mysearch_dataset(date_lst, "NHstatewide") # 2014-12-08 15% to 7%
  # subject_age
LAneworleans <- mysearch_dataset(date_lst, "LAneworleans") # 2011-05-09 30% to ~10%
  # location, lat, lng, outcome
FLstatewide <- mysearch_dataset(date_lst, "FLstatewide") # pre 2015-06-15, post 2016-10-31, 10% to 40%
  # location, subject_sex, subject_age
CAoakland <- mysearch_dataset(date_lst, "CAoakland") # pre 2016-12-26	 10% to 1%
  # subject_age

#daynight
OHcolumbus <- mysearch_dataset(sunriseset_lst, "OHcolumbus")
KYlouisville <- mysearch_dataset(sunriseset_lst, "KYlouisville")

# finding the differences here: 
CAoakland %>% filter(str_detect(date, "2017"))


date_df %>% filter(dataset_name == "CAoakland") 

```

```{r NH logistic regression, eval = FALSE}

 # 2014-12-08 15% to 7%

NHpre2014 <- NHstatewide %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date < ymd("2014-12-08"))

NHpost2014 <- NHstatewide %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date > ymd("2014-12-08"))

fit_NHpre2014 <- glm(citation_issued ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = NHpre2014, family = "binomial")
summary(fit_NHpre2014)

fit_NHpost2014 <- glm(citation_issued ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = NHpost2014, family = "binomial")
summary(fit_NHpost2014)

fit_NH <- glm(citation_issued ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = NHstatewide, family = "binomial")
summary(fit_NH)
```

```{r LA logistic regression, eval = FALSE}

LAneworleans <- DBI::dbGetQuery(con, "SELECT * FROM LAneworleans WHERE type = 'vehicular'")


# 2011-05-09 30% to ~10%
# location, lat, lng, outcome

LApre <- LAneworleans %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date < ymd("2011-05-09")) %>%
  select(subject_age, subject_race, subject_sex, search_conducted, officer_assignment, district, zone)

LApost <- LAneworleans %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date > ymd("2011-05-09")) %>%
  select(subject_age, subject_race, subject_sex, search_conducted, officer_assignment, district, zone)

fit_LApre2011 <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex + officer_assignment + district, data = LApre, family = "binomial")
summary(fit_LApre2011)

fit_LApost2011 <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex + officer_assignment + district, data = LApost, family = "binomial")
summary(fit_LApost2011)

fit_LA <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex + officer_assignment + district, data = LAneworleans, family = "binomial")
summary(fit_LA)
```

```{r FL logistic regression, eval = FALSE}

# pre 2015-06-15, post 2016-10-31, 10% to 40%
# location, subject_sex, subject_age

FLpre <- FLstatewide %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date < ymd("2015-06-15"))

FLpost <- FLstatewide %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date > ymd("2016-10-31"))
# post doesn't collect sex, age, ...
# so the pre and the aggregate models all have the same ... results?

fit_FLpre <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = FLpre, family = "binomial")
summary(fit_FLpre)

fit_FLpost <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race), data = FLpost, family = "binomial")
summary(fit_FLpost)

fit_FL <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = FLstatewide, family = "binomial")
summary(fit_FL)
```

```{r CAoak logistic, eval = FALSE}

# pre 2016-12-26	 10% to 1%
# subject_age

CApre <- CAoakland %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date < ymd("2016-12-26"))

CApost <- CAoakland %>% 
  mutate(date = lubridate::ymd(date)) %>%
  filter(date > ymd("2016-12-26"))


fit_CApre <- glm(search_conducted ~ as.factor(subject_race) + subject_sex, data = CApre, family = "binomial")
summary(fit_CApre)

fit_CApost <- glm(search_conducted ~ as.numeric(subject_age) + as.factor(subject_race) + subject_sex, data = CApost, family = "binomial")
summary(fit_CApost)

fit_LA <- glm(search_conducted ~ as.numeric(subject_age) + as.factor(subject_race) + subject_sex, data = CAoakland, family = "binomial")
summary(fit_LA)

```

```{r, eval = FALSE}
OHday <- OHcolumbus %>% filter(day_night == "day")
OHnight <- OHcolumbus %>% filter(day_night == "night")

fit_OHday <- glm(search_conducted ~ as.factor(subject_race) + subject_sex, data = OHday, family = "binomial")
fit_OHnight <- glm(search_conducted ~ as.factor(subject_race) + subject_sex, data = OHnight, family = "binomial")
fit_OH <- glm(search_conducted ~ as.factor(subject_race) + subject_sex, data = OHcolumbus, family = "binomial")

summary(fit_OHday)
summary(fit_OHnight)
summary(fit_OH)

KYday <- KYlouisville %>% filter(day_night == "day")
KYnight <- KYlouisville %>% filter(day_night == "night")

fit_KYday <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = KYday, family = "binomial")
summary(fit_KYday)

fit_KYnight <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = KYnight, family = "binomial")
summary(fit_KYnight)

fit_KY <- glm(search_conducted ~ as.numeric(subject_age)*as.factor(subject_race) + subject_sex, data = KYlouisville, family = "binomial")
summary(fit_KY)
```



